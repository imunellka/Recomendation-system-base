{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MzSv49iMF1_"
      },
      "source": [
        "# Matrix Factorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGoHyoipMF2B"
      },
      "source": [
        "<b>User-based</b> и <b>Item-based</b> методы фильтрации страдают от <i>data sparsity</i> и <i>scalability</i>, из-за этого мы точно не можем рекомендовать очень хорошо.\n",
        "\n",
        "<b>MF</b> помогает решить это из-за возможности уменьшения размерности матрицы рейтингов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04D2zA48MF2D"
      },
      "source": [
        "## Matrix Factorization : алгоритм\n",
        "<ol>\n",
        "    <li>Инициализация $P$ и $Q$ с рандомными значениями\n",
        "    <li>Для каждого примера $(u,i)\\in\\kappa$ выставить рейтинг $r_{u,i}$ :\n",
        "        <ul>\n",
        "            <li>вычислить  $\\hat{r}_{u,i} = q_{i}^{\\top} p_u$\n",
        "            <li>вычислить ошибку : $e_{u,i} = |r_{ui} - \\hat{r}_{u,i}|$\n",
        "            <li>обновить $p_u$ и $q_i$:\n",
        "                <ul>\n",
        "                    <li>$p_u \\leftarrow p_u + \\alpha\\cdot (e_{u,i}\\cdot q_i-\\lambda \\cdot p_u)$\n",
        "                    <li>$q_i \\leftarrow q_i + \\alpha\\cdot (e_{u,i}\\cdot p_u-\\lambda \\cdot q_i)$\n",
        "                </ul>\n",
        "        </ul>\n",
        "    <li> повторять до подбора оптимальных параметров\n",
        "</ol>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_ohlWURMF2F"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU6M-SAdZaii"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0cpIbLUZaii"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri4WXMGTZaij"
      },
      "outputs": [],
      "source": [
        "def ttsplit(examples, labels, test_size=0.1, verbose=0):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Train/Test split \")\n",
        "        print(100-test_size*100, \"% of training data\")\n",
        "        print(test_size*100, \"% of testing data\")\n",
        "\n",
        "    # split data into train and test sets\n",
        "    train_examples, test_examples, train_labels, test_labels = train_test_split(\n",
        "        examples,\n",
        "        labels,\n",
        "        test_size=0.1,\n",
        "        random_state=42,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # transform train and test examples to their corresponding one-hot representations\n",
        "    train_users = train_examples[:, 0]\n",
        "    test_users = test_examples[:, 0]\n",
        "\n",
        "    train_items = train_examples[:, 1]\n",
        "    test_items = test_examples[:, 1]\n",
        "\n",
        "    # Final training and test set\n",
        "    x_train = np.array(list(zip(train_users, train_items)))\n",
        "    x_test = np.array(list(zip(test_users, test_items)))\n",
        "\n",
        "    y_train = train_labels\n",
        "    y_test = test_labels\n",
        "\n",
        "    if verbose:\n",
        "        print()\n",
        "        print('number of training examples : ', x_train.shape)\n",
        "        print('number of training labels : ', y_train.shape)\n",
        "        print('number of test examples : ', x_test.shape)\n",
        "        print('number of test labels : ', y_test.shape)\n",
        "\n",
        "    return (x_train, x_test), (y_train, y_test)\n",
        "\n",
        "\n",
        "def mean_ratings(dataframe):\n",
        "    means = dataframe.groupby(by='userId', as_index=False)['rating'].mean()\n",
        "    return means\n",
        "\n",
        "\n",
        "def normalized_ratings(dataframe, norm_column=\"norm_rating\"):\n",
        "    \"\"\"\n",
        "    Нормализация рейтинга пользователя относительно общего среднего\n",
        "    \"\"\"\n",
        "    mean = mean_ratings(dataframe=dataframe)\n",
        "    norm = pd.merge(dataframe, mean, suffixes=('', '_mean'), on='userId')\n",
        "    norm[f'{norm_column}'] = norm['rating'] - norm['rating_mean']\n",
        "\n",
        "    return norm\n",
        "\n",
        "\n",
        "def rating_matrix(dataframe, column):\n",
        "    crosstab = pd.crosstab(dataframe.userId, dataframe.movieId, dataframe[f'{column}'], aggfunc=sum).fillna(0).values\n",
        "    matrix = csr_matrix(crosstab)\n",
        "    return matrix\n",
        "\n",
        "\n",
        "def scale_ratings(dataframe, scaled_column=\"scaled_rating\"):\n",
        "    dataframe[f\"{scaled_column}\"] = dataframe.rating / 5.0\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def get_examples(dataframe, labels_column=\"rating\"):\n",
        "    examples = dataframe[['userId', 'movieId']].values\n",
        "    labels = dataframe[f'{labels_column}'].values\n",
        "    return examples, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB0Uk785Zaik"
      },
      "outputs": [],
      "source": [
        "def ids_encoder(ratings):\n",
        "    \"\"\"\n",
        "        Энкодер для более удобной работы\n",
        "    \"\"\"\n",
        "    users = sorted(ratings['userId'].unique())\n",
        "    items = sorted(ratings['movieId'].unique())\n",
        "\n",
        "    # энкодер для пользователей и элементов\n",
        "    uencoder = LabelEncoder()\n",
        "    iencoder = LabelEncoder()\n",
        "\n",
        "    # fit\n",
        "    uencoder.fit(users)\n",
        "    iencoder.fit(items)\n",
        "\n",
        "    # перезапись ID\n",
        "    ratings.userId = uencoder.transform(ratings.userId.tolist())\n",
        "    ratings.movieId = iencoder.transform(ratings.movieId.tolist())\n",
        "\n",
        "    return ratings, uencoder, iencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOaP8ew3Zail"
      },
      "source": [
        "## Модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbUpj4o3Zail"
      },
      "outputs": [],
      "source": [
        "class MatrixFactorization:\n",
        "\n",
        "    def __init__(self, m, n, k=10, alpha=0.001, lamb=0.01):\n",
        "        \"\"\"\n",
        "\n",
        "        : param\n",
        "            - m : кол-во пользователей\n",
        "            - n : кол-во элементов\n",
        "            - k : длина факторов (для пользователей и элементов)\n",
        "            - alpha : learning rate\n",
        "            - lamb : regularizer\n",
        "        \"\"\"\n",
        "        np.random.seed(32)\n",
        "\n",
        "        # создаем матрицы P / Q\n",
        "        self.k = k\n",
        "        self.P = np.random.normal(size=(m, k))\n",
        "        self.Q = np.random.normal(size=(n, k))\n",
        "\n",
        "        # сохраняем гиперпараметры\n",
        "        self.alpha = alpha\n",
        "        self.lamb = lamb\n",
        "\n",
        "        # словарь для сохранения обучения\n",
        "        self.history = {\n",
        "            \"epochs\":[],\n",
        "            \"loss\":[],\n",
        "            \"val_loss\":[],\n",
        "            \"lr\":[]\n",
        "        }\n",
        "\n",
        "    def print_training_parameters(self):\n",
        "        print('Обучаем Matrix Factorization  ...')\n",
        "        print(f'k={self.k} \\t alpha={self.alpha} \\t lambda={self.lamb}')\n",
        "\n",
        "    def update_rule(self, u, i, error):\n",
        "        self.P[u] = self.P[u] + self.alpha * (error * self.Q[i] - self.lamb * self.P[u])\n",
        "        self.Q[i] = self.Q[i] + self.alpha * (error * self.P[u] - self.lamb * self.Q[i])\n",
        "\n",
        "    def mae(self,  x_train, y_train):\n",
        "        \"\"\"\n",
        "        функция возвращает MAE\n",
        "        \"\"\"\n",
        "        # кол-во в сэплте\n",
        "        M = x_train.shape[0]\n",
        "        error = 0\n",
        "        for pair, r in zip(x_train, y_train):\n",
        "            u, i = pair\n",
        "            error += abs(r - np.dot(self.P[u], self.Q[i]))\n",
        "        return error/M\n",
        "\n",
        "    def print_training_progress(self, epoch, epochs, error, val_error, steps=5):\n",
        "        if epoch == 1 or epoch % steps == 0 :\n",
        "                print(\"epoch {}/{} - loss : {} - val_loss : {}\".format(epoch, epochs, round(error,3), round(val_error,3)))\n",
        "\n",
        "    def learning_rate_schedule(self, epoch, target_epochs = 20):\n",
        "        if (epoch >= target_epochs) and (epoch % target_epochs == 0):\n",
        "                factor = epoch // target_epochs\n",
        "                self.alpha = self.alpha * (1 / (factor * 20))\n",
        "                print(\"\\nLearning Rate : {}\\n\".format(self.alpha))\n",
        "\n",
        "    def fit(self, x_train, y_train, validation_data, epochs=1000):\n",
        "        \"\"\"\n",
        "        Обучение на факторах P и Q с проверкой через тестовый набор данных\n",
        "\n",
        "        :param\n",
        "            - x_train : пара для обучения (u,i) где рейтинг известный\n",
        "            - y_train : набор рейтингов r_ui для пары (u,i)\n",
        "            - validation_data : tuple (x_test, y_test)\n",
        "            - epochs : кол-во валидаций\n",
        "\n",
        "        \"\"\"\n",
        "        self.print_training_parameters()\n",
        "\n",
        "        # валидация\n",
        "        x_test, y_test = validation_data\n",
        "\n",
        "        # цикл по эпохам\n",
        "        for epoch in range(1, epochs+1):\n",
        "\n",
        "            # для каждой пары (u,i) и рейтинга r (который известный)\n",
        "            for pair, r in zip(x_train, y_train):\n",
        "\n",
        "                # разкрываем пару значений\n",
        "                u,i = pair\n",
        "\n",
        "                # вычисляем предик\n",
        "                r_hat = np.dot(self.P[u], self.Q[i])\n",
        "\n",
        "                # считаем ошибку\n",
        "                e = abs(r - r_hat)\n",
        "\n",
        "                # обновляем\n",
        "                self.update_rule(u, i, e)\n",
        "\n",
        "\n",
        "\n",
        "            # финализация\n",
        "            error = self.mae(x_train, y_train)\n",
        "            val_error = self.mae(x_test, y_test)\n",
        "\n",
        "            # обновление словоря\n",
        "            self.history['epochs'].append(epoch)\n",
        "            self.history['loss'].append(error)\n",
        "            self.history['val_loss'].append(val_error)\n",
        "\n",
        "            # обновление истории\n",
        "            self.update_history(epoch, error, val_error)\n",
        "\n",
        "            # print\n",
        "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
        "\n",
        "        return self.history\n",
        "\n",
        "    def update_history(self, epoch, error, val_error):\n",
        "        self.history['epochs'].append(epoch)\n",
        "        self.history['loss'].append(error)\n",
        "        self.history['val_loss'].append(val_error)\n",
        "        self.history['lr'].append(self.alpha)\n",
        "\n",
        "    def evaluate(self, x_test, y_test):\n",
        "        \"\"\"\n",
        "        Вычисление глобальной ошибки на тестовой выборке\n",
        "        :param x_test : тестовая пара (u,i)\n",
        "        :param y_test : рейтинг r_ui для всех пар (u,i)\n",
        "        \"\"\"\n",
        "        error = self.mae(x_test, y_test)\n",
        "        print(f\"validation error : {round(error,3)}\")\n",
        "\n",
        "        return error\n",
        "\n",
        "    def predict(self, userid, itemid):\n",
        "        \"\"\"\n",
        "        Предикт для всех пользователей и элементов\n",
        "        :param userШd\n",
        "        :param itemId\n",
        "        :return r : предикт\n",
        "        \"\"\"\n",
        "\n",
        "        u = uencoder.transform([userid])[0]\n",
        "        i = iencoder.transform([itemid])[0]\n",
        "\n",
        "        # вычисление рейтинга\n",
        "        r = np.dot(self.P[u], self.Q[i])\n",
        "        return r\n",
        "\n",
        "    def recommend(self, userid, N=10):\n",
        "        \"\"\"\n",
        "        Топ N рекомендаций для переданного пользователя\n",
        "\n",
        "        :return(top_items,preds) : Топ N\n",
        "        \"\"\"\n",
        "\n",
        "        u = uencoder.transform([userid])[0]\n",
        "\n",
        "        # предикт\n",
        "        predictions = np.dot(self.P[u], self.Q.T)\n",
        "\n",
        "        # индекст Топ N\n",
        "        # только необходимое кол-во\n",
        "        top_items = self.iencoder.inverse_transform(top_idx)\n",
        "        top_idx = np.flip(np.argsort(predictions))[:N]\n",
        "        preds = predictions[top_idx]\n",
        "\n",
        "        return top_items, preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1LzMW3OZaim"
      },
      "outputs": [],
      "source": [
        "epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJRkZxV0Zain"
      },
      "source": [
        "### Сдетаем тест над данными"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55uxrVBOZain"
      },
      "outputs": [],
      "source": [
        "ratings = pd.read_csv('ratings.csv')\n",
        "movies = pd.read_csv('movies.csv')\n",
        "\n",
        "m = ratings.userId.nunique()   # всего пользователей\n",
        "n = ratings.movieId.nunique()   # всего элементов\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# получение данных в подготовленном виде\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = ttsplit(examples=raw_examples, labels=raw_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdCOoJqqZain"
      },
      "outputs": [],
      "source": [
        "# модель\n",
        "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit\n",
        "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t0LqMm-Zain"
      },
      "outputs": [],
      "source": [
        "MF.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPay6DwlZaio"
      },
      "source": [
        "### Нормализованные рейтинги"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3esdmc6Zaio"
      },
      "outputs": [],
      "source": [
        "ratings = pd.read_csv('ratings.csv')\n",
        "movies = pd.read_csv('movies.csv')\n",
        "\n",
        "m = ratings.userId.nunique()   # всего пользователей\n",
        "n = ratings.movieId.nunique()   # всего элементов\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# нормализация по среднему\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# подготовленные данные с нормализацией\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = ttsplit(examples=raw_examples, labels=raw_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN8S_4ebZaio"
      },
      "outputs": [],
      "source": [
        "# модель\n",
        "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit\n",
        "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHC3MFeVZaio"
      },
      "outputs": [],
      "source": [
        "MF.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQc5LTEaZaio"
      },
      "source": [
        "### Предикт"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hzclXP0RL8V"
      },
      "source": [
        "Латентные факторы в матрицах $P$ и $Q$ позволяют создавать предикт рейтингов для элементов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zWfr8YEZaip"
      },
      "outputs": [],
      "source": [
        "ratings.userid = uencoder.inverse_transform(ratings.userId.to_list())\n",
        "ratings.itemid = iencoder.inverse_transform(ratings.movieId.to_list())\n",
        "ratings.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjQN_N1WRKSm"
      },
      "outputs": [],
      "source": [
        "4.188679 + MF.predict(userid=1, itemid=1) # добавим средний рейтинг для предикта, т.к. ранее мы нормализовали"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}